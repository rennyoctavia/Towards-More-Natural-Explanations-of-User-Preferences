{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Template-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_US.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/renny/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "nltk.download('tagsets')\n",
    "\n",
    "from nltk.data import load\n",
    "from nltk.corpus import conll2000\n",
    "from nltk.chunk import regexp\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get similar tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_log_likelihood(a,b,c,d):\n",
    "    '''\n",
    "    Log-likelihood calculation (http://ucrel.lancs.ac.uk/llwizard.html): for a given tag and for each term that appears in reviews retrieved for that tag\n",
    "    :param a = number of reviews retrieved for tag that contain term\n",
    "    :param c = number of reviews retrieved for tag\n",
    "    :param b = number of documents that contain term\n",
    "    :param d = number of documents in the index\n",
    "    \n",
    "    '''\n",
    "    E1 = c*(a+b) / (c+d)\n",
    "    \n",
    "    E2 = d*(a+b) / (c+d)\n",
    "   \n",
    "    ll = 2*((a*math.log(a/E1)) + (b*math.log(b/E2)))\n",
    "\n",
    "    return ll\n",
    "\n",
    "def dump_pickle(filename,obj):\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(obj,f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_candidate(dict_candidates,d):\n",
    "    ll_scores = {}\n",
    "    for item,value in dict_candidates.items():\n",
    "        ll_scores[item] = count_log_likelihood(value['a'],value['b'],value['c'],d)\n",
    "    return {k: v for k, v in sorted(ll_scores.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only train split of tags for generating synthetic training data. If want to generate synonym for all tags, load all tags\n",
    "train_list_of_tags = load_pickle('data/dataset/splitted_tags/train_tags.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From list of unique pair of tag-movieID, filter only tags in the filetered tags\n",
    "\n",
    "dict_tag_movieId = {}\n",
    "dict_movieId_tag = {}\n",
    "#d = 0\n",
    "for tag, movieId in zip(list(movieId_tag['tag']), list(movieId_tag['movieId'])):\n",
    "    #if tag in cleaned_list_of_tags:\n",
    "    if tag in train_list_of_tags: # filter to only tags in train split    \n",
    "        #d = d+1\n",
    "        if tag in dict_tag_movieId:\n",
    "            dict_tag_movieId[tag].append(movieId)\n",
    "        else:\n",
    "            dict_tag_movieId[tag] = [movieId]\n",
    "        if movieId in dict_movieId_tag:\n",
    "            dict_movieId_tag[movieId].append(tag)\n",
    "        else:\n",
    "            dict_movieId_tag[movieId] = [tag]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_all_tags = {}\n",
    "\n",
    "#for tag in cleaned_list_of_tags:\n",
    "for tag in train_list_of_tags:\n",
    "    param_candidate_tags={}\n",
    "    movielens_id_hits = dict_tag_movieId[tag]\n",
    "    c = len(movielens_id_hits)\n",
    "    candidate_tags = {} #candidate tags , with value = number of movielens retrieved containing that cand tag\n",
    "    \n",
    "    for movieId in movielens_id_hits:\n",
    "        for cand_tag in dict_movieId_tag[movieId]: #candidate_tag will only appear once in one movie_lens ID\n",
    "            if cand_tag != tag: #to filtered out the 'tag' itself\n",
    "                if cand_tag not in candidate_tags:\n",
    "                    candidate_tags[cand_tag] = {'a':1, 'b' : len(dict_tag_movieId[cand_tag]), 'c' : c}\n",
    "                else:\n",
    "                    candidate_tags[cand_tag]['a'] = candidate_tags[cand_tag]['a'] + 1 #count how many movielense which tagged by tag also tagged by candidate tag\n",
    "                \n",
    "    parameters_all_tags[tag] = candidate_tags\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save top 10 synonyms in tsv\n",
    "\n",
    "out_file1 = open(\"data/tags_synonym/top_10_synonym_train.tsv\", 'wt')\n",
    "tsv_writer1 = csv.writer(out_file1, delimiter='\\t')\n",
    "tsv_writer1.writerow(['Tag'] + ['synonym'+str(i) for i in range(10)])\n",
    "sorted_synonyms={}\n",
    "d = len(dict_movieId_tag)\n",
    "for tag,value in parameters_all_tags.items():\n",
    "    top_10 = list(get_sorted_candidate(value,d).items())[0:10]\n",
    "    top_10 = [(x[0],(round(x[1], 2))) for x in top_10]\n",
    "    \n",
    "    tsv_writer1.writerow([tag] + top_10)\n",
    "    sorted_synonyms[tag] = dict(top_10)\n",
    "    \n",
    "dump_pickle('data/tags_synonym/top_10_synonym_train.pkl',sorted_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neo-noir': 25.02,\n",
       " 'film noir': 21.09,\n",
       " 'cruel': 20.97,\n",
       " 'multiple storylines': 20.78,\n",
       " 'frank miller': 20.55,\n",
       " 'amazing': 19.5,\n",
       " 'quentin tarantino': 18.67,\n",
       " 'robert rodriguez': 18.42,\n",
       " 'gratuitous violence': 18.42,\n",
       " 'jessica alba': 18.2}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "sorted_synonyms['monologue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
