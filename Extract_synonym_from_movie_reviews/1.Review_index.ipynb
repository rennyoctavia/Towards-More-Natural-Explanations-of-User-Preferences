{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers, exceptions\n",
    "from elasticsearch.client import IndicesClient\n",
    "import math\n",
    "es = Elasticsearch()\n",
    "INDEX_NAME = \"movie_reviews_4_10_5_no_stemming_shingle_max4\"\n",
    "FIELDS = ['movielens_ids','review','tags']\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_tv_from_tag(tag):\n",
    "    '''To get term vectors of reviews given tag\n",
    "    :param tag : tag text\n",
    "    :param multi_words : True if tag is multiwords, False if single word\n",
    "    :return : term_vectors for all movie reviews related to the tag\n",
    "    '''\n",
    "    #To check if the tag is multiwords\n",
    "    split_tag= tag.replace('-',' ').split()\n",
    "    len_tag = len(split_tag)\n",
    "    multi_words = True if len_tag>1 else False\n",
    "                                  \n",
    "    tag = tag.lower()\n",
    "    res = es.search(index=INDEX_NAME, body={'query': {'match_phrase': {'tags':tag}}},_source=False, size = 10000)['hits']\n",
    "    \n",
    "    term_vectors = {}\n",
    "    for item in res['hits']:\n",
    "        tv = es.termvectors(index=INDEX_NAME, id=item['_id'], fields='review', term_statistics=True).get('term_vectors',{}).get('review',{}).get('terms',{})\n",
    "        term_vectors[item['_id']] = tv\n",
    "    \n",
    "    return term_vectors,multi_words #Return unique reviews, as some written same reviews on different movies such as 'good', 'nice'\n",
    "\n",
    "def get_field_statistics(fields_list):\n",
    "    '''\n",
    "    Function to get field statistics, from non empty field\n",
    "    '''\n",
    "    field_statistic_dict = {}\n",
    "    \n",
    "    for field in fields_list:\n",
    "        \n",
    "        # Get random entity whith field = field is not empty, to get the field statistic\n",
    "        \n",
    "        body1={\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"filter\": {\n",
    "                \"exists\": {\n",
    "                  \"field\": field\n",
    "                }\n",
    "              },\n",
    "              \"must_not\": {\n",
    "                \"term\": {\n",
    "                  \"test.keyword\": \"\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "       \n",
    "        res = es.search(index = INDEX_NAME, body=body1,_source=False,size=1)\n",
    "        hits = res.get('hits',{}).get('hits',{})\n",
    "        ent_id = hits[0]['_id'] if len(hits) > 0 else None\n",
    "\n",
    "        field_statistic_dict[field] = es.termvectors(index = INDEX_NAME, id = ent_id,term_statistics=True, fields = field)['term_vectors'].get(field,{}).get('field_statistics',{})\n",
    "    return(field_statistic_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log likelihood calculation\n",
    "\n",
    "Log-likelihood calculation (http://ucrel.lancs.ac.uk/llwizard.html): for a given tag and for each term that appears in reviews retrieved for that tag For a given (tag, term) pair:\n",
    "- Corpus 1: reviews retrieved for tag\n",
    "  - Frequency of word: number of reviews retrieved for tag that contain term\n",
    "  - Corpus size: number of reviews retrieved for tag\n",
    "- Corpus 2: all reviews\n",
    "  - Frequency of word: number of documents that contain term\n",
    "  - Corpus size: number of documents in the index\n",
    "- Sort tags by LL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_log_likelihood(a,b,c,d):\n",
    "    '''\n",
    "    Log-likelihood calculation (http://ucrel.lancs.ac.uk/llwizard.html): for a given tag and for each term that appears in reviews retrieved for that tag\n",
    "    :param a = number of reviews retrieved for tag that contain term\n",
    "    :param c = number of reviews retrieved for tag\n",
    "    :param b = number of documents that contain term\n",
    "    :param d = number of documents in the index\n",
    "    \n",
    "    '''\n",
    "    E1 = c*(a+b) / (c+d)\n",
    "    \n",
    "    E2 = d*(a+b) / (c+d)\n",
    "   \n",
    "    ll = 2*((a*math.log(a/E1)) + (b*math.log(b/E2)))\n",
    "\n",
    "    return ll\n",
    "\n",
    "def get_ll(a_b_parameters, c, d):\n",
    "    '''\n",
    "    To get log likelihood score for all pairs of (tag,term) and return sorted by highst score\n",
    "    '''\n",
    "    ll_scores = {}\n",
    "    for term,param in a_b_parameters.items():\n",
    "        ll_scores[term] = count_log_likelihood(param['a'],param['b'],c,d)\n",
    "    return {k: v for k, v in sorted(ll_scores.items(), key=lambda item: item[1],reverse=True)}\n",
    "\n",
    "\n",
    "def get_parameters (tag,reviews_tv):\n",
    "    '''\n",
    "    Get parameter a, b,c,d for each (tag,term) pair\n",
    "    :param tag : original tag text\n",
    "    :tag_type  : 'single word' or 'multi words'    \n",
    "    '''\n",
    "    #reviews_tv = get_reviews_tv_from_tag(tag,multi_words)\n",
    "\n",
    "    a_b_parameters = {}\n",
    "    for doc, item in reviews_tv.items():\n",
    "        for term, tv in item.items():\n",
    "            key = (tag,term)\n",
    "            if key in a_b_parameters:\n",
    "                a_b_parameters[key]['a'] = a_b_parameters[key]['a'] + 1\n",
    "            else:\n",
    "                a_b_parameters[key] = {'a':1, 'b':tv['doc_freq']}\n",
    "    return a_b_parameters\n",
    "\n",
    "def get_sorted_terms (tag):\n",
    "    '''\n",
    "    Wrapper function to get sorted term for tag\n",
    "    '''\n",
    "\n",
    "    reviews_tv,multi_words = get_reviews_tv_from_tag(tag)\n",
    "    \n",
    "    c = len(reviews_tv) #Number of reviews hits\n",
    "    d = get_field_statistics(['review'])['review']['doc_count']\n",
    "    \n",
    "    #If number of reviews >=10\n",
    "    if c >= 10:\n",
    "        a_b_parameters= get_parameters(tag,reviews_tv)\n",
    "        sorted_ll = get_ll(a_b_parameters, c, d)\n",
    "        \n",
    "    #If number of reviews < 10, return empty dictionary\n",
    "    else:\n",
    "        sorted_ll = {}\n",
    "    return sorted_ll,multi_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get all Tags\n",
    "tags = pd.read_csv('Data/ml-20m/tags.csv')[['movieId','tag']]\n",
    "tags.dropna(inplace=True) # There are 16 tags with NAN values, drop the rows\n",
    "tags['tag'] = [str(x).lower() for x in tags['tag']] \n",
    "all_tags = list(set(tags['tag'])) \n",
    "len(all_tags)\n",
    "\n",
    "#Note : some tags might not be in the index, since not all movielens are mapped (up till now is 61%), \n",
    "#so might be there are tags assigned to movies that are not mapped yet\n",
    "#Total unique tags 35172 (lowered case),  total tags available in index if length of review limited to min 3 words = 14091 in index name 'movie_reviews_4_10_2',\n",
    "#if length of review limited to min 6 words, only 7368 tags available in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#As not all tags in index, so retrieve all tags available in index which has minimum 10 hits (10 reviews)\n",
    "tags_not_in_index = []\n",
    "tags_in_index = []\n",
    "for i,tag in enumerate(all_tags):\n",
    "    tag = tag.lower()\n",
    "    res = es.search(index=INDEX_NAME, body={'query': {'match_phrase': {'tags':tag}}},_source=False, size = 10)['hits']\n",
    "    \n",
    "    if len(res['hits'])==0:\n",
    "        tags_not_in_index.append(tag)\n",
    "        \n",
    "    elif len(res['hits']) == 10:\n",
    "        tags_in_index.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags_in_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the sorted terms based on LL\n",
    "\n",
    "- Some get related words :\n",
    "  - 'sadistic' : 'tarantino' 'django' 'quentin','jami','foxx'\n",
    "  - 'cute alien'  : 'et','sai','can','what','i'\n",
    "  - 'powerful' : hopkin, foster, nicholson, jodi\n",
    "\n",
    "\n",
    "- Some doesnt':\n",
    "  - 'misscariage of justice' : version, us, better, than\n",
    "  - 'child sacrifice' : love, movi\n",
    "  - 'dysfunctional family' : i, hoe, funni, great\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return top n terms based on LL for each all tags in index (for review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_tag= len(tags_in_index)\n",
    "sorted_terms_tag_multi_shingle_max2 = {}\n",
    "sorted_terms_tag_single_shingle_max2 = {}\n",
    "\n",
    "out_file1 = open(\"Data/sorted_terms/top_30_terms_per_tag(above_5)_multi_shingles_max2.tsv\", 'wt')\n",
    "out_file2 = open(\"Data/sorted_terms/top_30_terms_per_tag(above_5)_single_shingles_max2.tsv\", 'wt') \n",
    "\n",
    "#with open(\"Data/sorted_terms/top_5_terms_per_tag(above_5).tsv\", 'wt') as out_file:\n",
    "tsv_writer1 = csv.writer(out_file1, delimiter='\\t')\n",
    "tsv_writer2 = csv.writer(out_file2, delimiter='\\t')\n",
    "    \n",
    "for i,tag in enumerate(tags_in_index):\n",
    "    sorted_terms,multi_words = get_sorted_terms(tag)\n",
    "    if sorted_terms!={}:\n",
    "        keys = list(sorted_terms.keys())[0:30] # Return top-30\n",
    "        if multi_words == True:\n",
    "            tsv_writer1.writerow([tag] + ['('+str(x[1])+':'+str(sorted_terms[x])+')' for x in keys])\n",
    "            sorted_terms_tag_multi_shingle_max2[tag] = [(x[1],sorted_terms[x]) for x in keys]\n",
    "        else:\n",
    "            tsv_writer2.writerow([tag] + ['('+str(x[1])+':'+str(sorted_terms[x])+')' for x in keys])\n",
    "            sorted_terms_tag_single_shingle_max2[tag] = [(x[1],sorted_terms[x]) for x in keys]\n",
    "    \n",
    "    if (i+1)%100 == 0:\n",
    "        print(str(i+1),' done from ', num_tag)\n",
    "\n",
    "out_file1.close()\n",
    "out_file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file to pickle\n",
    "\n",
    "filename = 'Data/sorted_terms/sorted_terms_tag_multi_shingle_max2_top30.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(sorted_terms_tag_multi_shingle_max2,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'Data/sorted_terms/sorted_terms_tag_single_shingle_max2_top30.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(sorted_terms_tag_single_shingle_max2,outfile)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
