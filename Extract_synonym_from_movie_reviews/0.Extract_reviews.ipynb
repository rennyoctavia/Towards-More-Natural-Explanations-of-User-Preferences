{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Reviews from Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amazon_json(path):\n",
    "    g = open(path, 'r')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def load_json(filename):\n",
    "    '''\n",
    "    To load Json files\n",
    "    :param filename : filename to load\n",
    "    :return the object from Json file\n",
    "    '''\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def dump_json(filename,obj_to_dump):\n",
    "    '''\n",
    "    To dump (mainly) dictionaries to Json for further processing\n",
    "    :param filename : filename to save the jsonfile\n",
    "    '''\n",
    "    \n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(obj_to_dump, fp)\n",
    "    fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple preprocessing the reviews\n",
    "def preprocess(text):\n",
    "    list_punctuation = [\"!\",'\"','#','.',',','?']\n",
    "    text = text.replace('\\n',' ').strip()\n",
    "    for punct in list_punctuation:\n",
    "        text = text.replace(punct,' ')\n",
    "    text = ' '.join([x for x in text.split() if x!=''])\n",
    "    return(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = load_amazon_json('Data/Amazon/Movies_and_TV.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all items from the json into dictionary, key is running number 0 - n\n",
    "dictionary_all_reviews = {}\n",
    "for i,item in enumerate(reviews):\n",
    "    dictionary_all_reviews[i] = item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save the reviews in dictionary for each asin as key, and list of reviews as the values, only for reviews with length > 5\n",
    "dictionary_reviews = {}\n",
    "for item in dictionary_all_reviews:\n",
    "    review_text = dictionary_all_reviews.get(item,{}).get('reviewText','')\n",
    "    review_text = preprocess(review_text)\n",
    "    if (review_text != '') & (len(review_text.split())>5):\n",
    "        if dictionary_all_reviews[item]['asin'] not in dictionary_reviews:\n",
    "            dictionary_reviews[dictionary_all_reviews[item]['asin']] = [review_text]\n",
    "        else:\n",
    "            dictionary_reviews[dictionary_all_reviews[item]['asin']].append(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175907"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number of unique reviews for each ASIN (just for analysis)\n",
    "total_number_reviews = {}\n",
    "total_unique_reviews_per_asin = {}\n",
    "count_total_reviews = 0\n",
    "count_total_reviews_unique = 0\n",
    "for key in dictionary_reviews:\n",
    "    total_len=len(dictionary_reviews[key])\n",
    "    total_unique_len = len(list(dict.fromkeys(dictionary_reviews[key])))\n",
    "    total_number_reviews[key] = total_len\n",
    "    count_total_reviews = count_total_reviews + total_len\n",
    "    total_unique_reviews_per_asin[key] = total_unique_len\n",
    "    count_total_reviews_unique = count_total_reviews_unique + total_unique_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6572991"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_total_reviews_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mapped movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load mapped movielens id\n",
    "mapped_movielens_amazon=load_json('Data/mapped_ml_azn_4_10.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_mlId_asin = {} # dictionary with key:movielens id, value: list of asins\n",
    "reverse_mapped = {} # dictionary with key : tuple of asins, value: list of movielens ID (there asisns which are mapped to more than 1 movielens ID)\n",
    "for key in mapped_movielens_amazon:\n",
    "    asin_matched = [item[0] for item in mapped_movielens_amazon[key]['matched']]\n",
    "    #for item in mapped_movielens_amazon[key]['matched']:\n",
    "    mapped_mlId_asin[key] = asin_matched    \n",
    "    reverse_key = tuple(asin_matched)\n",
    "    if reverse_key in reverse_mapped:\n",
    "        reverse_mapped[reverse_key].append(key)\n",
    "    else:\n",
    "        reverse_mapped[reverse_key] = [key]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory with key : tuple of movielens_id, value : list of asins which mapped to movielens Ids\n",
    "# Due to the duplicates in title in amazon and movielens, there are ASINs which are mapped to more than one movielens ID\n",
    "multi_movielens_key_mapped = {}\n",
    "for asins in reverse_mapped:\n",
    "    key = tuple(reverse_mapped[asins])\n",
    "    multi_movielens_key_mapped[key]=asins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.read_csv('Data/ml-20m/tags.csv')[['movieId','tag']]\n",
    "tags_df.dropna(inplace=True) # There are 16 tags with NAN values, drop the rows\n",
    "tags_df['tag'] = [str(x).lower() for x in tags_df['tag']] \n",
    "tags_df.drop_duplicates(inplace=True) #Delete duplicate pair(movielens id, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get list of tags for each movielens id, in a form of dictionary with key: single movielens_Id, value: list of tags\n",
    "movieId_tag_dictionary = {}\n",
    "for ml_id, tag in zip(list(tags_df['movieId']),list(tags_df['tag'])):\n",
    "    ml_id = str(ml_id)\n",
    "    if ml_id not in movieId_tag_dictionary:\n",
    "        movieId_tag_dictionary[ml_id] = [tag]\n",
    "    else:\n",
    "        movieId_tag_dictionary[ml_id].append(tag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To make dictionary with key : tuple of movielens id, value: list of tags from each movielens id in the key, \n",
    "# the tuple of movielens id taken from the multi_movielens_key_mapped\n",
    "multi_movie_id_tag_dictionary = {}\n",
    "for key in multi_movielens_key_mapped:\n",
    "    tags_temp = []\n",
    "    for movie_id in key:\n",
    "        tags_temp = tags_temp + movieId_tag_dictionary.get(movie_id,[])\n",
    "\n",
    "    if tags_temp!=[]:\n",
    "        multi_movie_id_tag_dictionary[key] = list(set(tags_temp)) #make unique list of tags "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Reviews to Text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write data in one file (only movielens id that have tags assigned to it)\n",
    "# since there are limitation to review lenght, there are some asins with no review\n",
    "\n",
    "file2 = open(\"Data/reviews_txt_files/testing\",\"w\")\n",
    "file3 = open(\"Data/reviews_txt_files/testing_example\",\"w\") # This is just for example, for analysing format, etc. with smaller file\n",
    "\n",
    "for i,ml_Id in enumerate(multi_movielens_key_mapped):\n",
    "    if ml_Id in multi_movie_id_tag_dictionary:\n",
    "        asins = multi_movielens_key_mapped[ml_Id]\n",
    "        for each_asin in asins:\n",
    "            for review in list(dict.fromkeys(dictionary_reviews.get(each_asin,[]))):\n",
    "                review = review.lower().replace('\\n','')\n",
    "                file2.write(','.join(ml_Id)+'\\t'+review) \n",
    "                file2.write( \"\\n\")\n",
    "                \n",
    "                if i < 6:\n",
    "                    file3.write(','.join(ml_Id)+'\\t'+review) \n",
    "                    file3.write( \"\\n\")\n",
    "    \n",
    "file2.close()\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12791"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(movielens_id_in_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "#es.indices.delete(index='movie_reviews_4_10_5_no_stemming_shingle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize index\n",
    "\n",
    "INDEX_NAME = \"movie_reviews_4_10_5_no_stemming_shingle_max3\"\n",
    "\n",
    "\n",
    "#index setting using english analyzer (stemming included)\n",
    "INDEX_SETTINGS = {\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"number_of_shards\" : 1,\n",
    "            \"number_of_replicas\" : 1\n",
    "        }\n",
    "        \n",
    "    },\n",
    "    \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"review\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"term_vector\": \"with_positions\",\n",
    "                    \"analyzer\": \"english\"\n",
    "                },\n",
    "                \"tags\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"movielens_ids\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "#index setting if not including stemming\n",
    "INDEX_SETTINGS_NO_STEMMING = {\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"number_of_shards\" : 1,\n",
    "            \"number_of_replicas\" : 1\n",
    "        },\n",
    "        \n",
    "        \n",
    "        \"analysis\": {\n",
    "              \"analyzer\": {\n",
    "                \"my_english_analyzer\": {\n",
    "                  \"type\": \"standard\",\n",
    "                  \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    },\n",
    "    \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"review\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"term_vector\": \"with_positions\",\n",
    "                    \"analyzer\": \"my_english_analyzer\"\n",
    "                },\n",
    "                \"tags\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"movielens_ids\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "#Index setting with shingles\n",
    "INDEX_MAPPING = \n",
    "{\n",
    "    \"settings\" : {\n",
    "        \"index\" : {\n",
    "            \"number_of_shards\" : 1,\n",
    "            \"number_of_replicas\" : 1\n",
    "        },\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"my_english_analyzer\": {\n",
    "                  \"type\": \"custom\",\n",
    "                  \"tokenizer\": \"standard\",  \n",
    "                  \"stopwords\": \"_english_\",\n",
    "                  \"filter\" : [\"shingle-filter\",\"lowercase\",\"stop\"]  \n",
    "                    }\n",
    "                },\n",
    "             \"filter\":{\n",
    "                \"shingle-filter\":{\n",
    "                \"type\":\"shingle\",\n",
    "                \"min_shingle_size\":2,\n",
    "                \"max_shingle_size\":4,\n",
    "                \"output_unigrams\":True\n",
    "                }\n",
    "            }      \n",
    "        }     \n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"review\": {\n",
    "                \"type\": \"text\",\n",
    "                \"term_vector\": \"with_positions\",\n",
    "                \"analyzer\": \"my_english_analyzer\"\n",
    "            },\n",
    "             \"tags\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"movielens_ids\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not es.indices.exists(INDEX_NAME):  # create index if it doesn't exist\n",
    "    es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS_NO_STEMMING_SHINGLE )\n",
    "    print('Index created')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build index, by using the sorted_unique movie_reviews text file\n",
    "file1 = open('Data/reviews_txt_files/movie_reviews_sorted_unique_4_10_5.txt', 'r') \n",
    "Lines = file1.readlines() \n",
    "number_of_lines = len(Lines) \n",
    "#count = 0\n",
    "# Strips the newline character \n",
    "for i,line in enumerate(Lines): \n",
    "    line = line.split('\\t')\n",
    "    \n",
    "    movielens_id = line[0].split(',')\n",
    "    review = line[1].strip()\n",
    "    tags = multi_movie_id_tag_dictionary[tuple(movielens_id)]\n",
    "    es.index(index=INDEX_NAME, id=i, body={'movielens_ids': movielens_id, 'review': review, 'tags': tags})\n",
    "    \n",
    "    if ((i+1)%1000 == 0):\n",
    "        print('Done indexing for ' + str(i+1)  + ' lines out of ' + str(number_of_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Index name description:\n",
    "- movie_reviews_4_10_2 : with english analyzer(with stemming) limit word length > 2\n",
    "- movie_reviews_4_10_2_no_stemming : without stemming limit word length > 2\n",
    "- movie_reviews_4_10_3 : with english analyzer(with stemming) limit word length > 3 (not finished)\n",
    "- movie_reviews_4_10_5_no_stemming : without stemming and limit to word length > 5\n",
    "- movie_reviews_4_10_5 : with english analyzer(with stemming) limit word length > 5\n",
    "- movie_reviews_4_10_5_no_stemming_shingle : adding shingle (min 2, max 2) (with unigrams)\n",
    "- movie_reviews_4_10_5_no_stemming_shingle_max4 : adding shingle (min2, max4) (with unigrams)\n",
    "- movie_reviews_4_10_5_no_stemming_shingle_max3 : adding shingle (min2, max3) (with unigrams)\n",
    "- movie_reviews_4_10_5_no_stemming_shingle_only4 : only shingle 4 (without unigrams)\n",
    "- movie_reviews_4_10_5_no_stemming_shingle_only3 : only shingle 3 (without unigrams)\n",
    "- movie_reviews_4_10_5_no_stemming_shingle_only3 : only shingle 2 (without unigrams)\n",
    "\n",
    "file name description:\n",
    "- Data/reviews_txt_files/movie_reviews_sorted_unique_4_10_5.txt (length review > 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
